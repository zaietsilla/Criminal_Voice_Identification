{"cells":[{"cell_type":"code","execution_count":null,"id":"82676d49-2fa6-4505-9a59-85a1df144305","metadata":{"id":"82676d49-2fa6-4505-9a59-85a1df144305","outputId":"d56ee261-eac4-460e-c0a4-72e3103ec001"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -q Cython\n","!pip install -q nemo_toolkit[all]\n","!pip install -q pyannote.core\n","!pip install -q pyannote.metrics"]},{"cell_type":"markdown","id":"bf2b1d14-0336-4cd2-a0ed-951176f23e43","metadata":{"id":"bf2b1d14-0336-4cd2-a0ed-951176f23e43"},"source":["import json\n","import os\n","from nemo.collections.asr.models import ClusteringDiarizer\n","from omegaconf import OmegaConf"]},{"cell_type":"code","execution_count":null,"id":"dd2266f9-a901-4e87-ac3a-82a7d287238a","metadata":{"id":"dd2266f9-a901-4e87-ac3a-82a7d287238a"},"outputs":[],"source":["def read_num_speakers_from_rttm(rttm_file_path):\n","    speakers = set()\n","    with open(rttm_file_path, 'r') as file:\n","        for line in file:\n","            parts = line.strip().split()\n","            # Ідентифікатор спікера зазвичай знаходиться на 8-й позиції (починаючи з 0)\n","            speaker_id = parts[7]\n","            speakers.add(speaker_id)\n","    return len(speakers)"]},{"cell_type":"code","execution_count":null,"id":"89abdab7-c896-4ceb-9211-0d953abc42f8","metadata":{"id":"89abdab7-c896-4ceb-9211-0d953abc42f8","outputId":"d3d1dc61-38a7-4761-fe88-5e1ea950a1bb"},"outputs":[{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:08 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n","      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:10 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:16:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:16:10 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:10 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:10 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:10 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:10 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:11 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:11 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:16:11 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:11 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:16:11 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:11 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:11 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:11 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:12 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:12 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:16:12 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:13 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:16:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:13 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:16:13 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 25/25 [00:01<00:00, 20.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:14 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/cawnd/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:16:14 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:15 collections:302] Dataset loaded with 1198 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:16:15 collections:304] # 1198 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 19/19 [00:01<00:00,  9.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:17 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cawnd/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/cawnd/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:16:17 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:17 collections:302] Dataset loaded with 1906 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:16:17 collections:304] # 1906 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 30/30 [00:02<00:00, 11.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:21 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cawnd/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/cawnd/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:16:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:22 collections:302] Dataset loaded with 4595 items, total duration of  0.64 hours.\n","[NeMo I 2023-11-22 16:16:22 collections:304] # 4595 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 72/72 [00:05<00:00, 14.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:28 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cawnd/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:29 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/cawnd directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:16:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n","      warnings.warn(\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:30 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0052\t MISS 0.0117\t                 Diarization ER: 0.0790\t, Confusion ER:0.0621\n","[NeMo I 2023-11-22 16:16:30 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:16:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:16:30 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:30 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:30 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:30 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:30 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:30 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:30 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:16:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:16:30 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:30 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:30 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:30 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:30 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:30 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:16:31 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:31 classification_models:273] Perform streaming frame-level VAD\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:31 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:16:31 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 25/25 [00:00<00:00, 25.09it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:32 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dlast/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:16:32 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:32 collections:302] Dataset loaded with 1185 items, total duration of  0.62 hours.\n","[NeMo I 2023-11-22 16:16:32 collections:304] # 1185 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 19/19 [00:01<00:00, 10.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:34 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dlast/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dlast/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:16:34 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:35 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:35 collections:302] Dataset loaded with 1881 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:16:35 collections:304] # 1881 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 30/30 [00:02<00:00, 12.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:38 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dlast/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dlast/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:16:38 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:39 collections:302] Dataset loaded with 4519 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:16:39 collections:304] # 4519 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 71/71 [00:05<00:00, 13.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:45 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dlast/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:47 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dlast directory\n","[NeMo I 2023-11-22 16:16:47 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0018\t MISS 0.0028\t                 Diarization ER: 0.0206\t, Confusion ER:0.0160\n","[NeMo I 2023-11-22 16:16:47 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:16:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:16:47 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:16:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:47 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:47 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:47 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:47 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:47 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:16:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:16:47 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:47 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:47 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:48 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:48 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:16:48 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:48 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:16:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:48 collections:302] Dataset loaded with 10 items, total duration of  0.13 hours.\n","[NeMo I 2023-11-22 16:16:48 collections:304] # 10 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 10/10 [00:00<00:00, 19.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:48 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eddje/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:16:48 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:48 collections:302] Dataset loaded with 449 items, total duration of  0.24 hours.\n","[NeMo I 2023-11-22 16:16:48 collections:304] # 449 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  8.57it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:49 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eddje/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eddje/speaker_outputs/subsegments_scale1.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:50 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:50 collections:302] Dataset loaded with 711 items, total duration of  0.24 hours.\n","[NeMo I 2023-11-22 16:16:50 collections:304] # 711 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 12/12 [00:01<00:00, 10.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:51 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eddje/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eddje/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:16:51 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:52 collections:302] Dataset loaded with 1711 items, total duration of  0.24 hours.\n","[NeMo I 2023-11-22 16:16:52 collections:304] # 1711 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 27/27 [00:02<00:00, 12.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:54 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eddje/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:55 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eddje directory\n","[NeMo I 2023-11-22 16:16:55 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0069\t MISS 0.0023\t                 Diarization ER: 0.0092\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:16:55 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:16:55 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:55 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:16:55 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:16:55 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:55 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:55 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:55 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:55 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:16:55 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:16:55 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:55 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:16:55 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:16:55 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:16:55 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:55 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:16:56 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:16:56 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:16:56 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:56 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:16:56 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:56 collections:302] Dataset loaded with 15 items, total duration of  0.20 hours.\n","[NeMo I 2023-11-22 16:16:56 collections:304] # 15 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 15/15 [00:00<00:00, 19.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:57 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:57 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bmsyn/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:16:57 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:57 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:57 collections:302] Dataset loaded with 666 items, total duration of  0.35 hours.\n","[NeMo I 2023-11-22 16:16:57 collections:304] # 666 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 11/11 [00:01<00:00,  9.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:16:58 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bmsyn/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:16:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bmsyn/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:16:58 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:16:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:16:59 collections:302] Dataset loaded with 1065 items, total duration of  0.35 hours.\n","[NeMo I 2023-11-22 16:16:59 collections:304] # 1065 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 17/17 [00:01<00:00, 10.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:01 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bmsyn/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bmsyn/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:01 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:01 collections:302] Dataset loaded with 2577 items, total duration of  0.36 hours.\n","[NeMo I 2023-11-22 16:17:01 collections:304] # 2577 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 41/41 [00:03<00:00, 13.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:05 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bmsyn/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:05 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bmsyn directory\n","[NeMo I 2023-11-22 16:17:06 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0337\t MISS 0.0236\t                 Diarization ER: 0.0752\t, Confusion ER:0.0180\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:06 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:17:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:17:06 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:06 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:06 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:06 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:17:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:17:06 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:06 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:07 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:07 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:17:07 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:07 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:17:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:07 collections:302] Dataset loaded with 20 items, total duration of  0.28 hours.\n","[NeMo I 2023-11-22 16:17:07 collections:304] # 20 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 20/20 [00:00<00:00, 21.57it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:08 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/duvox/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:17:08 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:08 collections:302] Dataset loaded with 996 items, total duration of  0.52 hours.\n","[NeMo I 2023-11-22 16:17:08 collections:304] # 996 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 16/16 [00:01<00:00, 10.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:10 clustering_diarizer:389] Saved embedding files to nemo_output_directory/duvox/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/duvox/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:17:10 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:10 collections:302] Dataset loaded with 1579 items, total duration of  0.53 hours.\n","[NeMo I 2023-11-22 16:17:10 collections:304] # 1579 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 25/25 [00:02<00:00, 11.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:13 clustering_diarizer:389] Saved embedding files to nemo_output_directory/duvox/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/duvox/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:13 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:14 collections:302] Dataset loaded with 3801 items, total duration of  0.53 hours.\n","[NeMo I 2023-11-22 16:17:14 collections:304] # 3801 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 60/60 [00:04<00:00, 14.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:19 clustering_diarizer:389] Saved embedding files to nemo_output_directory/duvox/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:21 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/duvox directory\n","[NeMo I 2023-11-22 16:17:21 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0049\t MISS 0.0000\t                 Diarization ER: 0.0112\t, Confusion ER:0.0062\n","[NeMo I 2023-11-22 16:17:21 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:17:21 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:21 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:17:21 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:17:21 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:21 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:21 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:21 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:21 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:21 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:17:21 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:21 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:17:21 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:21 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:21 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:21 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:22 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:22 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:17:22 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 108.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:22 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:17:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:22 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:17:22 collections:304] # 1 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:22 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 83.86it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/fuzfh/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:17:22 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:22 collections:302] Dataset loaded with 27 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:17:22 collections:304] # 27 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:22 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fuzfh/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/fuzfh/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:17:22 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:22 collections:302] Dataset loaded with 43 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:17:22 collections:304] # 43 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:23 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fuzfh/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/fuzfh/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:23 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:23 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:23 collections:302] Dataset loaded with 104 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:17:23 collections:304] # 104 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:23 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fuzfh/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:23 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/fuzfh directory\n","[NeMo I 2023-11-22 16:17:23 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0227\t, Confusion ER:0.0227\n","[NeMo I 2023-11-22 16:17:23 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:17:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:17:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:17:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:23 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:23 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:23 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:17:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:17:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:24 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:24 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:17:24 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:24 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:17:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:24 collections:302] Dataset loaded with 10 items, total duration of  0.13 hours.\n","[NeMo I 2023-11-22 16:17:24 collections:304] # 10 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 10/10 [00:00<00:00, 17.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:25 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 18.45it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/byapz/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:17:25 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:25 collections:302] Dataset loaded with 446 items, total duration of  0.23 hours.\n","[NeMo I 2023-11-22 16:17:25 collections:304] # 446 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  7.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:26 clustering_diarizer:389] Saved embedding files to nemo_output_directory/byapz/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/byapz/speaker_outputs/subsegments_scale1.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:26 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:26 collections:302] Dataset loaded with 712 items, total duration of  0.24 hours.\n","[NeMo I 2023-11-22 16:17:26 collections:304] # 712 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 12/12 [00:01<00:00, 10.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:27 clustering_diarizer:389] Saved embedding files to nemo_output_directory/byapz/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/byapz/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:27 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:28 collections:302] Dataset loaded with 1717 items, total duration of  0.24 hours.\n","[NeMo I 2023-11-22 16:17:28 collections:304] # 1717 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 27/27 [00:01<00:00, 13.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:30 clustering_diarizer:389] Saved embedding files to nemo_output_directory/byapz/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:31 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/byapz directory\n","[NeMo I 2023-11-22 16:17:31 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0064\t MISS 0.0082\t                 Diarization ER: 0.1794\t, Confusion ER:0.1648\n","[NeMo I 2023-11-22 16:17:31 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:17:31 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:31 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:17:31 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:17:31 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:31 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:31 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:31 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:31 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:31 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:17:31 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:31 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:17:31 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:31 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:31 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:31 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:32 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:32 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:17:32 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:32 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:17:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:32 collections:302] Dataset loaded with 19 items, total duration of  0.26 hours.\n","[NeMo I 2023-11-22 16:17:32 collections:304] # 19 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 19/19 [00:00<00:00, 22.56it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:33 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.98it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:33 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eqsta/speaker_outputs/subsegments_scale0.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:33 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:33 collections:302] Dataset loaded with 909 items, total duration of  0.48 hours.\n","[NeMo I 2023-11-22 16:17:33 collections:304] # 909 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 15/15 [00:01<00:00, 11.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:34 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eqsta/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:35 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eqsta/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:17:35 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:35 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:35 collections:302] Dataset loaded with 1444 items, total duration of  0.48 hours.\n","[NeMo I 2023-11-22 16:17:35 collections:304] # 1444 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 23/23 [00:01<00:00, 12.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:37 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eqsta/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eqsta/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:37 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:38 collections:302] Dataset loaded with 3474 items, total duration of  0.48 hours.\n","[NeMo I 2023-11-22 16:17:38 collections:304] # 3474 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 55/55 [00:03<00:00, 14.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:43 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eqsta/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:43 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eqsta directory\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:44 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0062\t MISS 0.0065\t                 Diarization ER: 0.0855\t, Confusion ER:0.0728\n","[NeMo I 2023-11-22 16:17:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:17:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:17:44 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:45 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:45 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:45 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:17:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:17:45 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:45 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:45 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:45 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:17:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 56.20it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:45 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:17:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:45 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n","[NeMo I 2023-11-22 16:17:45 collections:304] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 3/3 [00:00<00:00,  7.95it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:46 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 38.68it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/fpfvy/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:17:46 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:46 collections:302] Dataset loaded with 124 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:17:46 collections:304] # 124 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:46 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fpfvy/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/fpfvy/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:17:46 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:46 collections:302] Dataset loaded with 196 items, total duration of  0.07 hours.\n","[NeMo I 2023-11-22 16:17:46 collections:304] # 196 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:47 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fpfvy/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/fpfvy/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:47 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:47 collections:302] Dataset loaded with 475 items, total duration of  0.07 hours.\n","[NeMo I 2023-11-22 16:17:47 collections:304] # 475 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  8.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:48 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fpfvy/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:48 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/fpfvy directory\n","[NeMo I 2023-11-22 16:17:48 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0018\t MISS 0.0000\t                 Diarization ER: 0.2083\t, Confusion ER:0.2065\n","[NeMo I 2023-11-22 16:17:49 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:17:49 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:49 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:17:49 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:17:49 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:49 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:49 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:49 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:49 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:17:49 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:17:49 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:49 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:17:49 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:17:49 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:17:49 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:49 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:17:49 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:17:49 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:17:49 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:50 classification_models:273] Perform streaming frame-level VAD\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:50 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:17:50 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 25/25 [00:01<00:00, 20.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:51 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bgvvt/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:17:51 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:51 collections:302] Dataset loaded with 1174 items, total duration of  0.61 hours.\n","[NeMo I 2023-11-22 16:17:51 collections:304] # 1174 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 19/19 [00:01<00:00, 10.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:53 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bgvvt/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bgvvt/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:17:53 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:54 collections:302] Dataset loaded with 1875 items, total duration of  0.62 hours.\n","[NeMo I 2023-11-22 16:17:54 collections:304] # 1875 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 30/30 [00:02<00:00, 12.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:17:57 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bgvvt/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:17:57 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bgvvt/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:17:57 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:17:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:17:58 collections:302] Dataset loaded with 4539 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:17:58 collections:304] # 4539 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 71/71 [00:04<00:00, 14.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:04 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bgvvt/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:05 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bgvvt directory\n","[NeMo I 2023-11-22 16:18:05 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0259\t MISS 0.0000\t                 Diarization ER: 0.0261\t, Confusion ER:0.0002\n","[NeMo I 2023-11-22 16:18:05 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:05 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:05 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:18:05 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:05 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:05 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:05 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:05 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:06 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:06 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:18:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:18:06 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:06 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:06 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:06 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:18:06 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:06 classification_models:273] Perform streaming frame-level VAD\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:06 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:18:06 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 25/25 [00:01<00:00, 24.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:07 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/fvhrk/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:18:08 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:08 collections:302] Dataset loaded with 1251 items, total duration of  0.66 hours.\n","[NeMo I 2023-11-22 16:18:08 collections:304] # 1251 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 20/20 [00:01<00:00, 10.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:10 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fvhrk/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/fvhrk/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:18:10 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:10 collections:302] Dataset loaded with 1984 items, total duration of  0.66 hours.\n","[NeMo I 2023-11-22 16:18:10 collections:304] # 1984 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 31/31 [00:02<00:00, 12.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:13 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fvhrk/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/fvhrk/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:18:13 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:14 collections:302] Dataset loaded with 4768 items, total duration of  0.66 hours.\n","[NeMo I 2023-11-22 16:18:14 collections:304] # 4768 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 75/75 [00:05<00:00, 13.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:21 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fvhrk/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:22 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/fvhrk directory\n","[NeMo I 2023-11-22 16:18:23 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0021\t MISS 0.0002\t                 Diarization ER: 0.0193\t, Confusion ER:0.0170\n","[NeMo I 2023-11-22 16:18:23 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:18:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:18:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:18:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:23 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:23 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:23 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:18:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:18:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:23 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:23 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:18:23 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:24 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:18:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:24 collections:302] Dataset loaded with 18 items, total duration of  0.24 hours.\n","[NeMo I 2023-11-22 16:18:24 collections:304] # 18 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 18/18 [00:00<00:00, 21.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:24 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/fowhl/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:18:25 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:25 collections:302] Dataset loaded with 881 items, total duration of  0.46 hours.\n","[NeMo I 2023-11-22 16:18:25 collections:304] # 881 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 14/14 [00:01<00:00,  8.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:27 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fowhl/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/fowhl/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:18:27 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:27 collections:302] Dataset loaded with 1401 items, total duration of  0.47 hours.\n","[NeMo I 2023-11-22 16:18:27 collections:304] # 1401 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 22/22 [00:01<00:00, 12.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:29 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fowhl/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/fowhl/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:18:29 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:30 collections:302] Dataset loaded with 3373 items, total duration of  0.47 hours.\n","[NeMo I 2023-11-22 16:18:30 collections:304] # 3373 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 53/53 [00:03<00:00, 13.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:35 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fowhl/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:36 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/fowhl directory\n","[NeMo I 2023-11-22 16:18:36 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0066\t MISS 0.0017\t                 Diarization ER: 0.0096\t, Confusion ER:0.0013\n","[NeMo I 2023-11-22 16:18:36 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:18:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:18:36 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:18:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:37 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:37 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:37 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:18:37 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:37 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:18:37 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:37 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:37 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:37 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:18:37 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:38 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:18:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:38 collections:302] Dataset loaded with 8 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:18:38 collections:304] # 8 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 8/8 [00:00<00:00, 15.69it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:38 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 22.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bjruf/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:18:38 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:38 collections:302] Dataset loaded with 344 items, total duration of  0.18 hours.\n","[NeMo I 2023-11-22 16:18:38 collections:304] # 344 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  8.36it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:39 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bjruf/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bjruf/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:18:39 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:39 collections:302] Dataset loaded with 549 items, total duration of  0.18 hours.\n","[NeMo I 2023-11-22 16:18:39 collections:304] # 549 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 9/9 [00:00<00:00,  9.97it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:40 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bjruf/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bjruf/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:18:40 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:40 collections:302] Dataset loaded with 1329 items, total duration of  0.18 hours.\n","[NeMo I 2023-11-22 16:18:40 collections:304] # 1329 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 21/21 [00:01<00:00, 12.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:42 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bjruf/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:43 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bjruf directory\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:43 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0348\t MISS 0.0271\t                 Diarization ER: 0.0629\t, Confusion ER:0.0011\n","[NeMo I 2023-11-22 16:18:43 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:18:43 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:43 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:18:43 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:43 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:43 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:43 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:43 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:44 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:44 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:18:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:18:44 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:44 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:44 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:44 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:44 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:44 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:18:44 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:44 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:18:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:44 collections:302] Dataset loaded with 11 items, total duration of  0.15 hours.\n","[NeMo I 2023-11-22 16:18:44 collections:304] # 11 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 11/11 [00:00<00:00, 20.63it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:45 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 19.09it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/auzru/speaker_outputs/subsegments_scale0.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:45 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:45 collections:302] Dataset loaded with 540 items, total duration of  0.28 hours.\n","[NeMo I 2023-11-22 16:18:45 collections:304] # 540 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  8.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:46 clustering_diarizer:389] Saved embedding files to nemo_output_directory/auzru/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/auzru/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:18:46 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:46 collections:302] Dataset loaded with 856 items, total duration of  0.29 hours.\n","[NeMo I 2023-11-22 16:18:46 collections:304] # 856 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 14/14 [00:01<00:00, 11.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:48 clustering_diarizer:389] Saved embedding files to nemo_output_directory/auzru/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/auzru/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:18:48 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:48 collections:302] Dataset loaded with 2056 items, total duration of  0.29 hours.\n","[NeMo I 2023-11-22 16:18:48 collections:304] # 2056 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 33/33 [00:02<00:00, 13.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:51 clustering_diarizer:389] Saved embedding files to nemo_output_directory/auzru/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:52 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/auzru directory\n","[NeMo I 2023-11-22 16:18:52 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0027\t MISS 0.0000\t                 Diarization ER: 0.0163\t, Confusion ER:0.0136\n","[NeMo I 2023-11-22 16:18:52 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:18:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:18:52 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:18:52 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:52 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:52 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:52 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:52 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:52 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:18:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:18:52 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:52 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:52 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:52 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:53 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:53 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:18:53 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:53 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:18:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:53 collections:302] Dataset loaded with 5 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:18:53 collections:304] # 5 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 5/5 [00:00<00:00, 12.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:53 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 30.20it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eoyaz/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:18:54 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:54 collections:302] Dataset loaded with 220 items, total duration of  0.12 hours.\n","[NeMo I 2023-11-22 16:18:54 collections:304] # 220 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  8.35it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:54 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eoyaz/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eoyaz/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:18:54 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:54 collections:302] Dataset loaded with 349 items, total duration of  0.12 hours.\n","[NeMo I 2023-11-22 16:18:54 collections:304] # 349 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  9.98it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:55 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eoyaz/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:55 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eoyaz/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:18:55 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:55 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:55 collections:302] Dataset loaded with 840 items, total duration of  0.12 hours.\n","[NeMo I 2023-11-22 16:18:55 collections:304] # 840 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 14/14 [00:01<00:00, 12.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:56 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eoyaz/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:57 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eoyaz directory\n","[NeMo I 2023-11-22 16:18:57 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0020\t MISS 0.0000\t                 Diarization ER: 0.0875\t, Confusion ER:0.0855\n","[NeMo I 2023-11-22 16:18:57 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:18:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:18:57 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:18:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:57 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:57 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:57 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:18:57 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:18:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:18:57 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:18:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:18:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:57 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:18:58 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:18:58 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:18:58 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 27.53it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:58 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:18:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:58 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:18:58 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 11.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:58 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 48.00it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dzsef/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:18:58 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:18:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:58 collections:302] Dataset loaded with 171 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:18:58 collections:304] # 171 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:59 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dzsef/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:18:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dzsef/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:18:59 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:18:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:18:59 collections:302] Dataset loaded with 271 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:18:59 collections:304] # 271 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.54it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:00 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dzsef/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dzsef/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:00 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:00 collections:302] Dataset loaded with 653 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:00 collections:304] # 653 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 11/11 [00:00<00:00, 12.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:01 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dzsef/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:01 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dzsef directory\n","[NeMo I 2023-11-22 16:19:01 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0000\t MISS 0.0000\t                 Diarization ER: 0.0000\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:19:01 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:01 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:01 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:01 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:19:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:02 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:02 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:02 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:02 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 30.12it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:02 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:02 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:19:02 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 11.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:03 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 33.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/aepyx/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:19:03 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:03 collections:302] Dataset loaded with 169 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:03 collections:304] # 169 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:03 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aepyx/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/aepyx/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:03 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:03 collections:302] Dataset loaded with 269 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:03 collections:304] # 269 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.02it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:04 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aepyx/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/aepyx/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:04 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:04 collections:302] Dataset loaded with 647 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:04 collections:304] # 647 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 11/11 [00:00<00:00, 11.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:05 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aepyx/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:06 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/aepyx directory\n","[NeMo I 2023-11-22 16:19:06 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0323\t MISS 0.0177\t                 Diarization ER: 0.1381\t, Confusion ER:0.0880\n","[NeMo I 2023-11-22 16:19:06 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:06 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:19:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:06 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:06 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:06 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:06 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:06 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:07 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:07 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:07 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 88.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:07 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:07 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:19:07 collections:304] # 1 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:07 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 93.35it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dohag/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:19:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:07 collections:302] Dataset loaded with 44 items, total duration of  0.02 hours.\n","[NeMo I 2023-11-22 16:19:07 collections:304] # 44 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:08 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dohag/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dohag/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:08 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:08 collections:302] Dataset loaded with 70 items, total duration of  0.02 hours.\n","[NeMo I 2023-11-22 16:19:08 collections:304] # 70 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:08 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dohag/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dohag/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:08 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:08 collections:302] Dataset loaded with 169 items, total duration of  0.02 hours.\n","[NeMo I 2023-11-22 16:19:08 collections:304] # 169 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.08it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:08 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dohag/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:09 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dohag directory\n","[NeMo I 2023-11-22 16:19:09 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0224\t MISS 0.0000\t                 Diarization ER: 0.0224\t, Confusion ER:0.0000\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:09 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:09 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:09 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:09 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:09 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:09 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:09 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:09 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:09 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:09 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:09 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:09 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:09 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:09 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:09 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:09 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:09 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:09 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:09 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 45.52it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:10 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:10 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n","[NeMo I 2023-11-22 16:19:10 collections:304] # 2 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 2/2 [00:00<00:00,  6.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:10 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 48.40it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eazeq/speaker_outputs/subsegments_scale0.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:10 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:10 collections:302] Dataset loaded with 96 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:19:10 collections:304] # 96 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.85it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:10 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eazeq/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eazeq/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:10 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:10 collections:302] Dataset loaded with 152 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:19:10 collections:304] # 152 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.82it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:11 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eazeq/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eazeq/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:11 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:11 collections:302] Dataset loaded with 371 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:19:11 collections:304] # 371 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  8.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:12 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eazeq/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:12 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eazeq directory\n","[NeMo I 2023-11-22 16:19:12 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0001\t MISS 0.0587\t                 Diarization ER: 0.0588\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:19:12 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:12 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:19:12 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:12 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:12 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:12 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:12 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:12 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:12 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:12 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:12 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:12 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:13 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:13 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:13 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:13 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:13 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:19:13 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 25/25 [00:01<00:00, 23.00it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:14 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/cvofp/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:19:15 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:15 collections:302] Dataset loaded with 1231 items, total duration of  0.65 hours.\n","[NeMo I 2023-11-22 16:19:15 collections:304] # 1231 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 20/20 [00:01<00:00, 10.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:17 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cvofp/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/cvofp/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:17 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:17 collections:302] Dataset loaded with 1953 items, total duration of  0.65 hours.\n","[NeMo I 2023-11-22 16:19:17 collections:304] # 1953 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 31/31 [00:02<00:00, 12.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:21 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cvofp/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/cvofp/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:22 collections:302] Dataset loaded with 4692 items, total duration of  0.65 hours.\n","[NeMo I 2023-11-22 16:19:22 collections:304] # 4692 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 74/74 [00:05<00:00, 14.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:29 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cvofp/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:30 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/cvofp directory\n","[NeMo I 2023-11-22 16:19:30 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0197\t MISS 0.0000\t                 Diarization ER: 0.0201\t, Confusion ER:0.0004\n","[NeMo I 2023-11-22 16:19:30 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:30 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:19:30 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:30 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:30 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:30 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:30 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:30 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:30 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:30 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:30 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:30 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:31 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:31 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:31 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 29.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:31 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:31 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:19:31 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 10.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:31 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 41.64it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dzxut/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:19:31 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:31 collections:302] Dataset loaded with 173 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:31 collections:304] # 173 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:32 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dzxut/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dzxut/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:32 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:32 collections:302] Dataset loaded with 278 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:32 collections:304] # 278 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:33 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dzxut/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:33 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dzxut/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:33 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:33 collections:302] Dataset loaded with 672 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:33 collections:304] # 672 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 11/11 [00:00<00:00, 11.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:34 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dzxut/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:34 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dzxut directory\n","[NeMo I 2023-11-22 16:19:34 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0267\t MISS 0.0207\t                 Diarization ER: 0.1829\t, Confusion ER:0.1355\n","[NeMo I 2023-11-22 16:19:35 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:35 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:35 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:35 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:19:35 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:35 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:35 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:35 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:35 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:35 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:35 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:35 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:35 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:35 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:35 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:35 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:35 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:35 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:35 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:36 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:36 collections:302] Dataset loaded with 24 items, total duration of  0.33 hours.\n","[NeMo I 2023-11-22 16:19:36 collections:304] # 24 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 24/24 [00:01<00:00, 21.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:37 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/diysk/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:19:37 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:37 collections:302] Dataset loaded with 1189 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:19:37 collections:304] # 1189 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 19/19 [00:01<00:00,  9.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:40 clustering_diarizer:389] Saved embedding files to nemo_output_directory/diysk/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/diysk/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:40 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:40 collections:302] Dataset loaded with 1886 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:19:40 collections:304] # 1886 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 30/30 [00:02<00:00, 11.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:43 clustering_diarizer:389] Saved embedding files to nemo_output_directory/diysk/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/diysk/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:43 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:19:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:44 collections:302] Dataset loaded with 4530 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:19:44 collections:304] # 4530 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 71/71 [00:04<00:00, 14.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:50 clustering_diarizer:389] Saved embedding files to nemo_output_directory/diysk/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:52 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/diysk directory\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:52 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0130\t MISS 0.0187\t                 Diarization ER: 0.0583\t, Confusion ER:0.0267\n","[NeMo I 2023-11-22 16:19:52 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:52 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:52 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:52 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:52 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:52 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:52 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:52 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:52 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:52 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:52 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:52 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:53 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:53 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:19:53 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:53 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:19:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:53 collections:302] Dataset loaded with 7 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:19:53 collections:304] # 7 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 7/7 [00:00<00:00, 14.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:54 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 24.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/clfcg/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:19:54 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:54 collections:302] Dataset loaded with 323 items, total duration of  0.17 hours.\n","[NeMo I 2023-11-22 16:19:54 collections:304] # 323 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  6.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:55 clustering_diarizer:389] Saved embedding files to nemo_output_directory/clfcg/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:55 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/clfcg/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:19:55 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:55 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:55 collections:302] Dataset loaded with 512 items, total duration of  0.17 hours.\n","[NeMo I 2023-11-22 16:19:55 collections:304] # 512 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  8.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:56 clustering_diarizer:389] Saved embedding files to nemo_output_directory/clfcg/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:19:56 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/clfcg/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:19:56 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:56 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:19:56 collections:302] Dataset loaded with 1233 items, total duration of  0.17 hours.\n","[NeMo I 2023-11-22 16:19:56 collections:304] # 1233 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 20/20 [00:01<00:00, 13.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:58 clustering_diarizer:389] Saved embedding files to nemo_output_directory/clfcg/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:59 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/clfcg directory\n","[NeMo I 2023-11-22 16:19:59 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0134\t MISS 0.0000\t                 Diarization ER: 0.6880\t, Confusion ER:0.6747\n","[NeMo I 2023-11-22 16:19:59 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:19:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:19:59 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:19:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:59 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:59 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:19:59 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:19:59 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:19:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:19:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:19:59 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:19:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:19:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:19:59 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:00 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:00 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:20:00 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  7.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:00 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:20:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:00 collections:302] Dataset loaded with 21 items, total duration of  0.29 hours.\n","[NeMo I 2023-11-22 16:20:00 collections:304] # 21 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 21/21 [00:00<00:00, 21.32it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:01 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bidnq/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:20:01 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:01 collections:302] Dataset loaded with 1069 items, total duration of  0.56 hours.\n","[NeMo I 2023-11-22 16:20:01 collections:304] # 1069 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 17/17 [00:01<00:00, 10.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:03 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bidnq/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bidnq/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:20:03 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:04 collections:302] Dataset loaded with 1693 items, total duration of  0.56 hours.\n","[NeMo I 2023-11-22 16:20:04 collections:304] # 1693 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 27/27 [00:02<00:00, 12.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:06 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bidnq/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bidnq/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:20:06 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:07 collections:302] Dataset loaded with 4069 items, total duration of  0.56 hours.\n","[NeMo I 2023-11-22 16:20:07 collections:304] # 4069 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 64/64 [00:04<00:00, 13.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:13 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bidnq/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:14 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bidnq directory\n","[NeMo I 2023-11-22 16:20:14 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0021\t MISS 0.0087\t                 Diarization ER: 0.0151\t, Confusion ER:0.0042\n","[NeMo I 2023-11-22 16:20:14 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:20:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:20:14 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:20:14 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:14 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:14 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:14 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:14 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:14 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:20:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:20:14 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:20:14 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:14 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:14 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:15 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:15 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:20:15 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 28.37it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:15 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:20:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:15 collections:302] Dataset loaded with 4 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:20:15 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 10.95it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:15 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 32.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bxcfq/speaker_outputs/subsegments_scale0.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:16 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:16 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:16 collections:302] Dataset loaded with 205 items, total duration of  0.11 hours.\n","[NeMo I 2023-11-22 16:20:16 collections:304] # 205 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:17 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bxcfq/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bxcfq/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:20:17 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:17 collections:302] Dataset loaded with 325 items, total duration of  0.11 hours.\n","[NeMo I 2023-11-22 16:20:17 collections:304] # 325 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  9.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:17 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bxcfq/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bxcfq/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:20:17 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:17 collections:302] Dataset loaded with 782 items, total duration of  0.11 hours.\n","[NeMo I 2023-11-22 16:20:17 collections:304] # 782 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 13/13 [00:01<00:00, 11.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:19 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bxcfq/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:19 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bxcfq directory\n","[NeMo I 2023-11-22 16:20:19 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0000\t MISS 0.0040\t                 Diarization ER: 0.0040\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:20:19 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:20:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:20:19 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:20:19 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:19 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:19 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:19 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:20 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:20 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:20:20 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:20 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:20:20 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:20:20 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:20 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:20 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:20 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:20 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:20:20 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:20 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:20:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:20 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:20 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 25/25 [00:01<00:00, 22.11it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:22 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/aorju/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:20:22 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:22 collections:302] Dataset loaded with 1134 items, total duration of  0.59 hours.\n","[NeMo I 2023-11-22 16:20:22 collections:304] # 1134 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 18/18 [00:01<00:00,  9.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:24 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aorju/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/aorju/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:20:24 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:25 collections:302] Dataset loaded with 1813 items, total duration of  0.60 hours.\n","[NeMo I 2023-11-22 16:20:25 collections:304] # 1813 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 29/29 [00:02<00:00, 11.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:28 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aorju/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/aorju/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:20:28 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:29 collections:302] Dataset loaded with 4379 items, total duration of  0.61 hours.\n","[NeMo I 2023-11-22 16:20:29 collections:304] # 4379 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 69/69 [00:04<00:00, 14.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:35 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aorju/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:36 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/aorju directory\n","[NeMo I 2023-11-22 16:20:36 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0253\t MISS 0.0157\t                 Diarization ER: 0.1054\t, Confusion ER:0.0644\n","[NeMo I 2023-11-22 16:20:36 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:20:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:20:36 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:20:36 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:36 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:36 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:36 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:36 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:36 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:20:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:20:36 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:20:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:37 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:37 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:37 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:20:37 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:37 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:20:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:37 collections:302] Dataset loaded with 14 items, total duration of  0.19 hours.\n","[NeMo I 2023-11-22 16:20:37 collections:304] # 14 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 14/14 [00:00<00:00, 19.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:38 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/cpebh/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:20:38 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:38 collections:302] Dataset loaded with 686 items, total duration of  0.36 hours.\n","[NeMo I 2023-11-22 16:20:38 collections:304] # 686 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 11/11 [00:01<00:00,  9.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:40 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cpebh/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/cpebh/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:20:40 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:40 collections:302] Dataset loaded with 1086 items, total duration of  0.36 hours.\n","[NeMo I 2023-11-22 16:20:40 collections:304] # 1086 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 17/17 [00:01<00:00, 12.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:41 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cpebh/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/cpebh/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:20:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:42 collections:302] Dataset loaded with 2606 items, total duration of  0.36 hours.\n","[NeMo I 2023-11-22 16:20:42 collections:304] # 2606 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 41/41 [00:02<00:00, 13.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:46 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cpebh/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:47 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/cpebh directory\n","[NeMo I 2023-11-22 16:20:47 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0012\t MISS 0.0000\t                 Diarization ER: 0.0012\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:20:47 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:20:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:20:47 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:20:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:47 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:47 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:47 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:47 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:47 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:20:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:20:47 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:20:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:47 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:47 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:48 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:48 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:20:48 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 13.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:48 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:20:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:48 collections:302] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2023-11-22 16:20:48 collections:304] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:00<00:00, 19.96it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:48 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 18.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bvqnu/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:20:49 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:49 collections:302] Dataset loaded with 593 items, total duration of  0.31 hours.\n","[NeMo I 2023-11-22 16:20:49 collections:304] # 593 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  9.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:50 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bvqnu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bvqnu/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:20:50 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:50 collections:302] Dataset loaded with 942 items, total duration of  0.31 hours.\n","[NeMo I 2023-11-22 16:20:50 collections:304] # 942 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 15/15 [00:01<00:00, 11.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:53 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bvqnu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:20:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bvqnu/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:20:53 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:54 collections:302] Dataset loaded with 2264 items, total duration of  0.31 hours.\n","[NeMo I 2023-11-22 16:20:54 collections:304] # 2264 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 36/36 [00:02<00:00, 12.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:57 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bvqnu/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:58 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bvqnu directory\n","[NeMo I 2023-11-22 16:20:58 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0036\t MISS 0.0000\t                 Diarization ER: 0.0761\t, Confusion ER:0.0725\n","[NeMo I 2023-11-22 16:20:58 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:20:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:20:58 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:20:58 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:58 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:58 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:58 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:58 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:20:58 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:20:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:20:58 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:20:58 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:20:58 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:58 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:20:59 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:20:59 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:20:59 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 61.04it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:59 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:20:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:59 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n","[NeMo I 2023-11-22 16:20:59 collections:304] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 3/3 [00:00<00:00,  9.18it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:59 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 43.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:20:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bvyvm/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:20:59 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:20:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:20:59 collections:302] Dataset loaded with 122 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:20:59 collections:304] # 122 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:00 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bvyvm/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bvyvm/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:21:00 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:00 collections:302] Dataset loaded with 194 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:21:00 collections:304] # 194 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.98it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:00 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bvyvm/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bvyvm/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:21:00 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:00 collections:302] Dataset loaded with 466 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:21:00 collections:304] # 466 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  9.68it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:01 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bvyvm/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:02 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bvyvm directory\n","[NeMo I 2023-11-22 16:21:02 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0073\t MISS 0.0000\t                 Diarization ER: 0.0073\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:21:02 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:21:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:21:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:21:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:02 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:21:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:21:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:03 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:03 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:21:03 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:03 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:21:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:03 collections:302] Dataset loaded with 23 items, total duration of  0.32 hours.\n","[NeMo I 2023-11-22 16:21:03 collections:304] # 23 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 23/23 [00:01<00:00, 20.39it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:04 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eauve/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:21:04 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:04 collections:302] Dataset loaded with 1200 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:21:04 collections:304] # 1200 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 19/19 [00:01<00:00, 10.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:06 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eauve/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eauve/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:21:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:07 collections:302] Dataset loaded with 1902 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:21:07 collections:304] # 1902 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 30/30 [00:02<00:00, 12.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:10 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eauve/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eauve/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:21:10 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:11 collections:302] Dataset loaded with 4567 items, total duration of  0.63 hours.\n","[NeMo I 2023-11-22 16:21:11 collections:304] # 4567 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 72/72 [00:05<00:00, 14.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:17 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eauve/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:19 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eauve directory\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:19 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0024\t MISS 0.0000\t                 Diarization ER: 0.0079\t, Confusion ER:0.0055\n","[NeMo I 2023-11-22 16:21:19 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:21:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:21:19 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:19 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:19 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:19 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:19 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:19 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:19 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:21:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:21:19 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:19 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:19 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:19 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:20 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:20 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:21:20 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 35.78it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:20 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:21:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:20 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n","[NeMo I 2023-11-22 16:21:20 collections:304] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 3/3 [00:00<00:00,  9.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:20 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 41.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/cqfmj/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:21:20 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:21 collections:302] Dataset loaded with 117 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:21:21 collections:304] # 117 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:21 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cqfmj/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/cqfmj/speaker_outputs/subsegments_scale1.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:21 collections:302] Dataset loaded with 186 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:21:21 collections:304] # 186 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.59it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:22 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cqfmj/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/cqfmj/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:21:22 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:22 collections:302] Dataset loaded with 449 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:21:22 collections:304] # 449 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  9.59it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:23 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cqfmj/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:23 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/cqfmj directory\n","[NeMo I 2023-11-22 16:21:23 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0029\t MISS 0.0000\t                 Diarization ER: 0.0029\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:21:23 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:21:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:21:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:21:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:23 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:23 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:23 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:21:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:21:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:24 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:24 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:21:24 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:24 classification_models:273] Perform streaming frame-level VAD\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:24 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:21:24 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 25/25 [00:01<00:00, 21.68it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:25 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dkabn/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:21:25 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:26 collections:302] Dataset loaded with 1174 items, total duration of  0.62 hours.\n","[NeMo I 2023-11-22 16:21:26 collections:304] # 1174 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 19/19 [00:01<00:00, 11.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:28 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dkabn/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dkabn/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:21:28 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:28 collections:302] Dataset loaded with 1865 items, total duration of  0.62 hours.\n","[NeMo I 2023-11-22 16:21:28 collections:304] # 1865 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 30/30 [00:02<00:00, 12.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:31 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dkabn/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dkabn/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:21:31 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:32 collections:302] Dataset loaded with 4491 items, total duration of  0.62 hours.\n","[NeMo I 2023-11-22 16:21:32 collections:304] # 4491 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 71/71 [00:05<00:00, 13.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:40 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dkabn/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:42 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dkabn directory\n","[NeMo I 2023-11-22 16:21:42 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0108\t MISS 0.0001\t                 Diarization ER: 0.0168\t, Confusion ER:0.0060\n","[NeMo I 2023-11-22 16:21:42 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:21:42 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:42 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:21:42 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:21:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:42 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:42 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:42 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:42 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:42 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:21:42 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:42 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:21:42 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:42 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:42 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:43 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:43 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:21:43 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 64.19it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:43 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:21:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:43 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n","[NeMo I 2023-11-22 16:21:43 collections:304] # 2 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 2/2 [00:00<00:00,  6.45it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:43 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 51.78it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eucfa/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:21:43 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:43 collections:302] Dataset loaded with 85 items, total duration of  0.04 hours.\n","[NeMo I 2023-11-22 16:21:43 collections:304] # 85 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.08it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:44 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eucfa/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eucfa/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:21:44 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:44 collections:302] Dataset loaded with 135 items, total duration of  0.04 hours.\n","[NeMo I 2023-11-22 16:21:44 collections:304] # 135 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.04it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:44 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eucfa/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eucfa/speaker_outputs/subsegments_scale2.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:44 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:44 collections:302] Dataset loaded with 326 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:21:44 collections:304] # 326 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  9.32it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:45 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eucfa/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:45 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eucfa directory\n","[NeMo I 2023-11-22 16:21:45 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0056\t MISS 0.0000\t                 Diarization ER: 0.0413\t, Confusion ER:0.0357\n","[NeMo I 2023-11-22 16:21:45 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:21:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:21:45 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:21:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:45 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:45 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:45 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:21:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:21:45 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:45 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:46 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:46 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:21:46 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:46 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:21:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:46 collections:302] Dataset loaded with 16 items, total duration of  0.22 hours.\n","[NeMo I 2023-11-22 16:21:46 collections:304] # 16 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 16/16 [00:00<00:00, 20.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:47 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dgvwu/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:21:47 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:47 collections:302] Dataset loaded with 807 items, total duration of  0.43 hours.\n","[NeMo I 2023-11-22 16:21:47 collections:304] # 807 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 13/13 [00:01<00:00, 10.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:49 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dgvwu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dgvwu/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:21:49 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:49 collections:302] Dataset loaded with 1281 items, total duration of  0.43 hours.\n","[NeMo I 2023-11-22 16:21:49 collections:304] # 1281 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 21/21 [00:01<00:00, 11.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:51 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dgvwu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dgvwu/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:21:51 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:52 collections:302] Dataset loaded with 3078 items, total duration of  0.43 hours.\n","[NeMo I 2023-11-22 16:21:52 collections:304] # 3078 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 49/49 [00:03<00:00, 14.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:56 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dgvwu/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:57 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dgvwu directory\n","[NeMo I 2023-11-22 16:21:57 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0030\t MISS 0.0036\t                 Diarization ER: 0.3684\t, Confusion ER:0.3618\n","[NeMo I 2023-11-22 16:21:57 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:21:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:21:57 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:21:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:57 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:57 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:57 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:21:57 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:21:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:21:57 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:21:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:21:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:57 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:21:58 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:21:58 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:21:58 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.12it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:58 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:21:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:58 collections:302] Dataset loaded with 6 items, total duration of  0.07 hours.\n","[NeMo I 2023-11-22 16:21:58 collections:304] # 6 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 6/6 [00:00<00:00, 13.69it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:59 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 27.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/aggyz/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:21:59 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:59 collections:302] Dataset loaded with 271 items, total duration of  0.14 hours.\n","[NeMo I 2023-11-22 16:21:59 collections:304] # 271 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:59 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aggyz/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:21:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/aggyz/speaker_outputs/subsegments_scale1.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:21:59 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:21:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:21:59 collections:302] Dataset loaded with 430 items, total duration of  0.14 hours.\n","[NeMo I 2023-11-22 16:21:59 collections:304] # 430 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  9.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:00 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aggyz/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/aggyz/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:00 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:00 collections:302] Dataset loaded with 1035 items, total duration of  0.14 hours.\n","[NeMo I 2023-11-22 16:22:00 collections:304] # 1035 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 17/17 [00:01<00:00, 13.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:02 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aggyz/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:02 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/aggyz directory\n","[NeMo I 2023-11-22 16:22:02 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0013\t MISS 0.0030\t                 Diarization ER: 0.1345\t, Confusion ER:0.1302\n","[NeMo I 2023-11-22 16:22:02 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:02 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:03 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:03 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:03 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:03 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:03 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:03 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 35.67it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:03 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:03 collections:302] Dataset loaded with 3 items, total duration of  0.04 hours.\n","[NeMo I 2023-11-22 16:22:03 collections:304] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 3/3 [00:00<00:00,  8.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:04 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 52.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/erslt/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:22:04 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:04 collections:302] Dataset loaded with 122 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:04 collections:304] # 122 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.54it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:04 clustering_diarizer:389] Saved embedding files to nemo_output_directory/erslt/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/erslt/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:04 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:04 collections:302] Dataset loaded with 194 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:04 collections:304] # 194 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.97it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:05 clustering_diarizer:389] Saved embedding files to nemo_output_directory/erslt/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/erslt/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:05 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:05 collections:302] Dataset loaded with 468 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:05 collections:304] # 468 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00, 13.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:06 clustering_diarizer:389] Saved embedding files to nemo_output_directory/erslt/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:06 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/erslt directory\n","[NeMo I 2023-11-22 16:22:06 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0062\t MISS 0.0000\t                 Diarization ER: 0.0062\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:22:06 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:06 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:07 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:07 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:07 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:07 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:07 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:07 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:07 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:07 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:07 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:07 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:07 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:07 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:07 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:07 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:07 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:08 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:08 collections:302] Dataset loaded with 19 items, total duration of  0.26 hours.\n","[NeMo I 2023-11-22 16:22:08 collections:304] # 19 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 19/19 [00:00<00:00, 22.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:08 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:09 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/fijfi/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:22:09 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:09 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:09 collections:302] Dataset loaded with 912 items, total duration of  0.48 hours.\n","[NeMo I 2023-11-22 16:22:09 collections:304] # 912 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 15/15 [00:01<00:00,  9.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:10 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fijfi/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/fijfi/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:11 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:11 collections:302] Dataset loaded with 1442 items, total duration of  0.48 hours.\n","[NeMo I 2023-11-22 16:22:11 collections:304] # 1442 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 23/23 [00:02<00:00, 11.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:13 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fijfi/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/fijfi/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:13 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:14 collections:302] Dataset loaded with 3472 items, total duration of  0.48 hours.\n","[NeMo I 2023-11-22 16:22:14 collections:304] # 3472 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 55/55 [00:03<00:00, 14.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:19 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fijfi/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:20 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/fijfi directory\n","[NeMo I 2023-11-22 16:22:20 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0073\t MISS 0.0000\t                 Diarization ER: 0.0190\t, Confusion ER:0.0117\n","[NeMo I 2023-11-22 16:22:20 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:20 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:20 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:20 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:20 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:20 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:20 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:20 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:20 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:20 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:20 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:20 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:20 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:20 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:20 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:20 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:21 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:21 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:21 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 41.96it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:21 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:21 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n","[NeMo I 2023-11-22 16:22:21 collections:304] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 3/3 [00:00<00:00,  9.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:21 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 59.10it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/eguui/speaker_outputs/subsegments_scale0.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:21 collections:302] Dataset loaded with 109 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:21 collections:304] # 109 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:22 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eguui/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/eguui/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:22 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:22 collections:302] Dataset loaded with 174 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:22 collections:304] # 174 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:22 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eguui/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/eguui/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:22 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:22 collections:302] Dataset loaded with 418 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:22 collections:304] # 418 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 7/7 [00:00<00:00, 10.07it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:23 clustering_diarizer:389] Saved embedding files to nemo_output_directory/eguui/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:24 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/eguui directory\n","[NeMo I 2023-11-22 16:22:24 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0995\t MISS 0.0000\t                 Diarization ER: 0.0995\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:22:24 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:24 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:24 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:24 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:24 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:24 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:24 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:24 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:24 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:24 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:24 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:24 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:25 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:25 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:25 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:25 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:25 collections:302] Dataset loaded with 22 items, total duration of  0.30 hours.\n","[NeMo I 2023-11-22 16:22:25 collections:304] # 22 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 22/22 [00:01<00:00, 19.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:26 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/bpzsc/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:22:26 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:26 collections:302] Dataset loaded with 1081 items, total duration of  0.57 hours.\n","[NeMo I 2023-11-22 16:22:26 collections:304] # 1081 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:28 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bpzsc/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/bpzsc/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:29 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:29 collections:302] Dataset loaded with 1710 items, total duration of  0.57 hours.\n","[NeMo I 2023-11-22 16:22:29 collections:304] # 1710 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 27/27 [00:02<00:00, 11.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:32 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bpzsc/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/bpzsc/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:32 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:33 collections:302] Dataset loaded with 4120 items, total duration of  0.57 hours.\n","[NeMo I 2023-11-22 16:22:33 collections:304] # 4120 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 65/65 [00:04<00:00, 13.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:39 clustering_diarizer:389] Saved embedding files to nemo_output_directory/bpzsc/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:40 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/bpzsc directory\n","[NeMo I 2023-11-22 16:22:40 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0043\t MISS 0.0000\t                 Diarization ER: 0.0067\t, Confusion ER:0.0024\n","[NeMo I 2023-11-22 16:22:40 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:40 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:40 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:40 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:40 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:40 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:40 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:40 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:41 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:41 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:41 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 32.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:41 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:41 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:22:41 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00,  9.28it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:42 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 36.86it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/fqrnu/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:22:42 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:42 collections:302] Dataset loaded with 170 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:22:42 collections:304] # 170 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:42 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fqrnu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/fqrnu/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:42 collections:302] Dataset loaded with 271 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:22:42 collections:304] # 271 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.74it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:43 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fqrnu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/fqrnu/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:43 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:43 collections:302] Dataset loaded with 655 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:22:43 collections:304] # 655 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 11/11 [00:01<00:00, 10.29it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:44 clustering_diarizer:389] Saved embedding files to nemo_output_directory/fqrnu/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:45 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/fqrnu directory\n","[NeMo I 2023-11-22 16:22:45 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0002\t MISS 0.0149\t                 Diarization ER: 0.0437\t, Confusion ER:0.0287\n","[NeMo I 2023-11-22 16:22:45 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:45 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:45 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:45 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:45 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:45 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:45 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:46 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:46 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:46 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:46 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:46 collections:302] Dataset loaded with 14 items, total duration of  0.19 hours.\n","[NeMo I 2023-11-22 16:22:46 collections:304] # 14 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 14/14 [00:00<00:00, 16.97it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:47 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dxbbt/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:22:47 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:47 collections:302] Dataset loaded with 709 items, total duration of  0.37 hours.\n","[NeMo I 2023-11-22 16:22:47 collections:304] # 709 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 12/12 [00:01<00:00,  8.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:49 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dxbbt/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dxbbt/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:49 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:49 collections:302] Dataset loaded with 1124 items, total duration of  0.37 hours.\n","[NeMo I 2023-11-22 16:22:49 collections:304] # 1124 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 18/18 [00:01<00:00, 11.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:51 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dxbbt/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dxbbt/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:22:51 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:22:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:51 collections:302] Dataset loaded with 2697 items, total duration of  0.37 hours.\n","[NeMo I 2023-11-22 16:22:51 collections:304] # 2697 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 43/43 [00:02<00:00, 14.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:55 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dxbbt/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:56 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dxbbt directory\n","[NeMo I 2023-11-22 16:22:56 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0024\t MISS 0.0000\t                 Diarization ER: 0.1065\t, Confusion ER:0.1041\n","[NeMo I 2023-11-22 16:22:56 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:22:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:22:56 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:22:56 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:56 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:56 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:56 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:56 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:22:56 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:22:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:22:56 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:22:56 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:22:56 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:56 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:22:58 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:22:58 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:22:58 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 33.03it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:58 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:22:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:58 collections:302] Dataset loaded with 4 items, total duration of  0.06 hours.\n","[NeMo I 2023-11-22 16:22:58 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00,  8.96it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:58 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 35.13it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/aiqwk/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:22:58 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:58 collections:302] Dataset loaded with 202 items, total duration of  0.11 hours.\n","[NeMo I 2023-11-22 16:22:58 collections:304] # 202 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.97it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:59 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aiqwk/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:22:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/aiqwk/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:22:59 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:22:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:22:59 collections:302] Dataset loaded with 321 items, total duration of  0.11 hours.\n","[NeMo I 2023-11-22 16:22:59 collections:304] # 321 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  7.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:00 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aiqwk/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/aiqwk/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:00 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:00 collections:302] Dataset loaded with 775 items, total duration of  0.11 hours.\n","[NeMo I 2023-11-22 16:23:00 collections:304] # 775 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 13/13 [00:01<00:00, 11.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:01 clustering_diarizer:389] Saved embedding files to nemo_output_directory/aiqwk/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:02 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/aiqwk directory\n","[NeMo I 2023-11-22 16:23:02 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0088\t MISS 0.0026\t                 Diarization ER: 0.2862\t, Confusion ER:0.2748\n","[NeMo I 2023-11-22 16:23:02 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:23:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:02 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:02 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:02 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:03 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:03 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:03 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:03 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:03 collections:302] Dataset loaded with 25 items, total duration of  0.34 hours.\n","[NeMo I 2023-11-22 16:23:03 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 25/25 [00:01<00:00, 22.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:04 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/epygx/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:04 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:05 collections:302] Dataset loaded with 1132 items, total duration of  0.59 hours.\n","[NeMo I 2023-11-22 16:23:05 collections:304] # 1132 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 18/18 [00:01<00:00, 10.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:07 clustering_diarizer:389] Saved embedding files to nemo_output_directory/epygx/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/epygx/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:07 collections:302] Dataset loaded with 1806 items, total duration of  0.60 hours.\n","[NeMo I 2023-11-22 16:23:07 collections:304] # 1806 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 29/29 [00:02<00:00, 12.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:11 clustering_diarizer:389] Saved embedding files to nemo_output_directory/epygx/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/epygx/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:11 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:12 collections:302] Dataset loaded with 4367 items, total duration of  0.60 hours.\n","[NeMo I 2023-11-22 16:23:12 collections:304] # 4367 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 69/69 [00:04<00:00, 14.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:18 clustering_diarizer:389] Saved embedding files to nemo_output_directory/epygx/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:19 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/epygx directory\n","[NeMo I 2023-11-22 16:23:19 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0088\t MISS 0.0154\t                 Diarization ER: 0.1693\t, Confusion ER:0.1450\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:19 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:19 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:19 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:19 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:19 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:19 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:19 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:19 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:19 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:20 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:20 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:20 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:20 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:20 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:20 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 40.10it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:20 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:20 collections:302] Dataset loaded with 3 items, total duration of  0.04 hours.\n","[NeMo I 2023-11-22 16:23:20 collections:304] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 3/3 [00:00<00:00,  8.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:21 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 38.58it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/cwbvu/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:21 collections:302] Dataset loaded with 127 items, total duration of  0.07 hours.\n","[NeMo I 2023-11-22 16:23:21 collections:304] # 127 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:21 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cwbvu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/cwbvu/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:21 collections:302] Dataset loaded with 202 items, total duration of  0.07 hours.\n","[NeMo I 2023-11-22 16:23:21 collections:304] # 202 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.63it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:22 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cwbvu/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/cwbvu/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:22 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:22 collections:302] Dataset loaded with 485 items, total duration of  0.07 hours.\n","[NeMo I 2023-11-22 16:23:22 collections:304] # 485 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00, 10.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:23 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cwbvu/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:23 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/cwbvu directory\n","[NeMo I 2023-11-22 16:23:23 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0022\t MISS 0.0000\t                 Diarization ER: 0.0979\t, Confusion ER:0.0956\n","[NeMo I 2023-11-22 16:23:23 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:23:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:23 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:23 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:23 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:23 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:23 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:24 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:24 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:24 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 80.57it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:24 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:24 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:23:24 collections:304] # 1 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:24 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/euqef/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:24 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:24 collections:302] Dataset loaded with 25 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:23:24 collections:304] # 25 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:25 clustering_diarizer:389] Saved embedding files to nemo_output_directory/euqef/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/euqef/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:25 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:25 collections:302] Dataset loaded with 40 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:23:25 collections:304] # 40 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:25 clustering_diarizer:389] Saved embedding files to nemo_output_directory/euqef/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/euqef/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:25 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:25 collections:302] Dataset loaded with 97 items, total duration of  0.01 hours.\n","[NeMo I 2023-11-22 16:23:25 collections:304] # 97 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/3] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:25 clustering_diarizer:389] Saved embedding files to nemo_output_directory/euqef/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00, 19.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:26 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/euqef directory\n","[NeMo I 2023-11-22 16:23:26 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0576\t MISS 0.0297\t                 Diarization ER: 0.0873\t, Confusion ER:0.0000\n","[NeMo I 2023-11-22 16:23:26 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:26 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:26 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:26 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:26 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:26 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:26 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:26 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:26 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:26 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:26 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:26 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:26 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:26 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:26 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:26 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:26 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:26 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:26 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.81it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:27 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:27 collections:302] Dataset loaded with 6 items, total duration of  0.08 hours.\n","[NeMo I 2023-11-22 16:23:27 collections:304] # 6 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 6/6 [00:00<00:00, 12.97it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:27 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 26.29it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/ezxso/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:27 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:27 collections:302] Dataset loaded with 285 items, total duration of  0.15 hours.\n","[NeMo I 2023-11-22 16:23:27 collections:304] # 285 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.68it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:28 clustering_diarizer:389] Saved embedding files to nemo_output_directory/ezxso/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/ezxso/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:28 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:28 collections:302] Dataset loaded with 451 items, total duration of  0.15 hours.\n","[NeMo I 2023-11-22 16:23:28 collections:304] # 451 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  9.57it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:29 clustering_diarizer:389] Saved embedding files to nemo_output_directory/ezxso/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/ezxso/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:29 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:29 collections:302] Dataset loaded with 1085 items, total duration of  0.15 hours.\n","[NeMo I 2023-11-22 16:23:29 collections:304] # 1085 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 17/17 [00:01<00:00, 11.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:31 clustering_diarizer:389] Saved embedding files to nemo_output_directory/ezxso/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:31 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/ezxso directory\n","[NeMo I 2023-11-22 16:23:31 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0036\t MISS 0.0000\t                 Diarization ER: 0.2314\t, Confusion ER:0.2279\n","[NeMo I 2023-11-22 16:23:32 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:32 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:32 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:32 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:23:32 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:32 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:32 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:32 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:32 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:32 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:32 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:32 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:32 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:32 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:32 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:32 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:32 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:32 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:32 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 32.08it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:32 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:32 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:23:32 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 10.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:33 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 41.45it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:33 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/cadba/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:33 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:33 collections:302] Dataset loaded with 185 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:23:33 collections:304] # 185 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.94it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:33 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cadba/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/cadba/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:34 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:34 collections:302] Dataset loaded with 293 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:23:34 collections:304] # 293 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:34 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cadba/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/cadba/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:34 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:34 collections:302] Dataset loaded with 707 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:23:34 collections:304] # 707 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 12/12 [00:00<00:00, 12.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:35 clustering_diarizer:389] Saved embedding files to nemo_output_directory/cadba/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:36 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/cadba directory\n","[NeMo I 2023-11-22 16:23:36 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0074\t MISS 0.0189\t                 Diarization ER: 0.2651\t, Confusion ER:0.2388\n","[NeMo I 2023-11-22 16:23:36 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:36 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:23:36 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:36 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:36 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:36 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:36 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:36 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:36 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:36 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:36 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:36 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:37 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:37 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:37 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 30.78it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:37 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:37 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:23:37 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 10.42it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:37 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 43.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/crylr/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:37 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:38 collections:302] Dataset loaded with 168 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:23:38 collections:304] # 168 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/3] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.95it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:38 clustering_diarizer:389] Saved embedding files to nemo_output_directory/crylr/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/crylr/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:38 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:38 collections:302] Dataset loaded with 268 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:23:38 collections:304] # 268 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.37it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:39 clustering_diarizer:389] Saved embedding files to nemo_output_directory/crylr/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/crylr/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:39 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:39 collections:302] Dataset loaded with 649 items, total duration of  0.09 hours.\n","[NeMo I 2023-11-22 16:23:39 collections:304] # 649 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 11/11 [00:00<00:00, 11.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:40 clustering_diarizer:389] Saved embedding files to nemo_output_directory/crylr/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:41 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/crylr directory\n","[NeMo I 2023-11-22 16:23:41 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0005\t MISS 0.0061\t                 Diarization ER: 0.2349\t, Confusion ER:0.2282\n","[NeMo I 2023-11-22 16:23:41 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:41 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:41 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:41 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:23:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:41 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:41 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:41 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:41 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:41 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:41 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:41 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:41 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:41 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:41 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:41 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 34.52it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:41 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:41 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2023-11-22 16:23:41 collections:304] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00, 10.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:42 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 35.45it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/dxokr/speaker_outputs/subsegments_scale0.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:42 collections:302] Dataset loaded with 193 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:23:42 collections:304] # 193 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.21it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:43 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dxokr/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/dxokr/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:43 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:43 collections:302] Dataset loaded with 307 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:23:43 collections:304] # 307 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.81it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:44 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dxokr/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/dxokr/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:44 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:44 collections:302] Dataset loaded with 739 items, total duration of  0.10 hours.\n","[NeMo I 2023-11-22 16:23:44 collections:304] # 739 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 12/12 [00:00<00:00, 12.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:45 clustering_diarizer:389] Saved embedding files to nemo_output_directory/dxokr/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:46 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/dxokr directory\n","[NeMo I 2023-11-22 16:23:46 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0066\t MISS 0.0000\t                 Diarization ER: 0.0351\t, Confusion ER:0.0285\n","[NeMo I 2023-11-22 16:23:46 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2023-11-22 16:23:46 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:46 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2023-11-22 16:23:46 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2023-11-22 16:23:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:46 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:46 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:46 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2023-11-22 16:23:46 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n","[NeMo I 2023-11-22 16:23:46 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:46 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2023-11-22 16:23:46 common:913] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2023-11-22 16:23:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2023-11-22 16:23:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:46 features:289] PADDING: 16\n","[NeMo I 2023-11-22 16:23:47 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","[NeMo I 2023-11-22 16:23:47 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2023-11-22 16:23:47 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:47 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2023-11-22 16:23:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:47 collections:302] Dataset loaded with 19 items, total duration of  0.26 hours.\n","[NeMo I 2023-11-22 16:23:47 collections:304] # 19 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 19/19 [00:00<00:00, 20.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:48 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["\n","creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, nemo_output_directory/crorm/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2023-11-22 16:23:48 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:48 collections:302] Dataset loaded with 954 items, total duration of  0.50 hours.\n","[NeMo I 2023-11-22 16:23:48 collections:304] # 954 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/3] extract embeddings: 100%|██████████| 15/15 [00:01<00:00, 10.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:50 clustering_diarizer:389] Saved embedding files to nemo_output_directory/crorm/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, nemo_output_directory/crorm/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2023-11-22 16:23:50 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:50 collections:302] Dataset loaded with 1512 items, total duration of  0.50 hours.\n","[NeMo I 2023-11-22 16:23:50 collections:304] # 1512 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/3] extract embeddings: 100%|██████████| 24/24 [00:02<00:00, 11.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:52 clustering_diarizer:389] Saved embedding files to nemo_output_directory/crorm/speaker_outputs/embeddings\n","[NeMo I 2023-11-22 16:23:52 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, nemo_output_directory/crorm/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2023-11-22 16:23:52 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2023-11-22 16:23:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2023-11-22 16:23:53 collections:302] Dataset loaded with 3633 items, total duration of  0.50 hours.\n","[NeMo I 2023-11-22 16:23:53 collections:304] # 3633 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/3] extract embeddings: 100%|██████████| 57/57 [00:04<00:00, 13.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:58 clustering_diarizer:389] Saved embedding files to nemo_output_directory/crorm/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2023-11-22 16:23:59 clustering_diarizer:464] Outputs are saved in /workspace/nemo_output_directory/crorm directory\n","[NeMo I 2023-11-22 16:23:59 der:176] Cumulative Results for collar 0.5 sec and ignore_overlap True: \n","     FA: 0.0012\t MISS 0.0007\t                 Diarization ER: 0.0092\t, Confusion ER:0.0073\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import json\n","import os\n","from nemo.collections.asr.models import ClusteringDiarizer\n","from omegaconf import OmegaConf\n","\n","# Шлях до папок\n","wav_folder = 'voxconverse_test_wav'\n","rttm_folder = 'voxconverse_test_rttm'\n","manifest_folder = 'nemo_manifests'\n","output_dir_base = 'nemo_output_directory'\n","\n","# Створення папки для маніфестів, якщо вона ще не існує\n","os.makedirs(manifest_folder, exist_ok=True)\n","\n","# Перебір усіх wav файлів у папці\n","for wav_file in os.listdir(wav_folder):\n","    if wav_file.endswith('.wav'):\n","        # Визначення шляхів\n","        wav_path = os.path.join(wav_folder, wav_file)\n","        rttm_path = os.path.join(rttm_folder, wav_file.replace('.wav', '.rttm'))\n","        manifest_path = os.path.join(manifest_folder, wav_file.replace('.wav', '.json'))\n","\n","        # Читання кількості спікерів з RTTM файла (припустимо, що ви вже маєте функцію для цього)\n","        num_speakers = read_num_speakers_from_rttm(rttm_path)\n","\n","        # Створення маніфесту для кожного wav файлу\n","        meta = {\n","            'audio_filepath': wav_path,\n","            'offset': 0,\n","            'duration': None,\n","            'label': 'infer',\n","            'text': '-',\n","            'num_speakers': num_speakers,\n","            'rttm_filepath': rttm_path,\n","            'uem_filepath' : None\n","        }\n","        with open(manifest_path, 'w') as fp:\n","            json.dump(meta, fp)\n","            fp.write('\\n')\n","\n","        # Шлях до вашого існуючого .yaml файлу\n","        MODEL_CONFIG = 'diar_infer_general.yaml'\n","\n","        # Завантаження існуючої конфігурації\n","        config = OmegaConf.load(MODEL_CONFIG)\n","\n","        # Оновлення шляху до маніфесту та вихідної директорії\n","        manifest_path = os.path.join(manifest_folder, wav_file.replace('.wav', '.json'))\n","        output_dir = os.path.join(output_dir_base, wav_file.replace('.wav', ''))\n","\n","        config.diarizer.manifest_filepath = manifest_path\n","        config.diarizer.out_dir = output_dir\n","\n","        # Виконання діаризації з оновленою конфігурацією\n","        sd_model = ClusteringDiarizer(cfg=config)\n","        sd_model.diarize()"]},{"cell_type":"code","execution_count":null,"id":"f7ef61b5-c5a6-4119-966d-6368df674989","metadata":{"id":"f7ef61b5-c5a6-4119-966d-6368df674989","outputId":"d108dc8e-721f-4bf1-f63f-60a7eace9b43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Diarization Error Rate: 0.14\n","Average Jaccard Error Rate: 0.39\n","Average Insertion Error Rate: 1.03\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Python Library</th>\n","      <th>Average Diarization Error Rate</th>\n","      <th>Average Jaccard Error Rate</th>\n","      <th>Average Insertion Error Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SpeechBrain</td>\n","      <td>0.135694</td>\n","      <td>0.3889</td>\n","      <td>1.025886</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Python Library  Average Diarization Error Rate  Average Jaccard Error Rate  \\\n","0    SpeechBrain                        0.135694                      0.3889   \n","\n","   Average Insertion Error Rate  \n","0                      1.025886  "]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","from pyannote.core import Annotation, Segment\n","from pyannote.metrics.diarization import DiarizationErrorRate, JaccardErrorRate\n","from pyannote.metrics.identification import IdentificationErrorRate\n","from pyannote.metrics.detection import DetectionErrorRate\n","\n","def load_rttm(file_path):\n","    annotation = Annotation()\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            parts = line.strip().split()\n","            start = float(parts[3])\n","            duration = float(parts[4])\n","            label = parts[7]\n","            annotation[Segment(start, start + duration)] = label\n","    return annotation\n","\n","rttm_folder = 'voxconverse_test_rttm'  # Шлях до папки з RTTM файлами\n","file_names = []  # Список для зберігання назв файлів\n","\n","# Перебір всіх файлів у папці\n","for file in os.listdir(rttm_folder):\n","    if file.endswith('.rttm'):\n","        # Додавання назви файлу без розширення .rttm до списку\n","        file_names.append(os.path.splitext(file)[0])\n","\n","# Створення екземпляра DiarizationErrorRate\n","der_metric = DiarizationErrorRate(collar=0.5)\n","jer_metric = JaccardErrorRate(collar=0.5)\n","ier_metric = IdentificationErrorRate(collar=0.5)\n","\n","# Масив для зберігання значень DER для кожної пари\n","error_rates_der = []\n","error_rates_jer = []\n","error_rates_ier = []\n","\n","for file_name in file_names:\n","    reference_path = f'voxconverse_test_rttm/{file_name}.rttm'\n","    hypothesis_path = f'nemo_output_directory/{file_name}/pred_rttms/{file_name}.rttm'\n","\n","    reference_annotation = load_rttm(reference_path)\n","    hypothesis_annotation = load_rttm(hypothesis_path)\n","\n","    # Calculate metrics\n","    der = der_metric(reference_annotation, hypothesis_annotation)\n","    jer = jer_metric(reference_annotation, hypothesis_annotation)\n","    ier = ier_metric(reference_annotation, hypothesis_annotation)\n","\n","    error_rates_der.append(der)\n","    error_rates_jer.append(jer)\n","    error_rates_ier.append(ier)\n","\n","# Розрахунок середнього DER\n","average_der = sum(error_rates_der) / len(error_rates_der)\n","print(f\"Average Diarization Error Rate: {average_der:.2f}\")\n","\n","average_jer = sum(error_rates_jer) / len(error_rates_jer)\n","print(f\"Average Jaccard Error Rate: {average_jer:.2f}\")\n","\n","average_ier = sum(error_rates_ier) / len(error_rates_ier)\n","print(f\"Average Insertion Error Rate: {average_ier:.2f}\")\n","\n","df_result = pd.DataFrame([{\n","    'Python Library': 'SpeechBrain',\n","    'Average Diarization Error Rate': average_der,\n","    'Average Jaccard Error Rate': average_jer,\n","    'Average Insertion Error Rate': average_ier,\n","}])\n","\n","display(df_result)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}