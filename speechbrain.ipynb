{"cells":[{"cell_type":"code","execution_count":null,"id":"07101985-7e7d-44ba-adcf-2bc79ef69cdb","metadata":{"id":"07101985-7e7d-44ba-adcf-2bc79ef69cdb","outputId":"5d504917-6f16-4bdd-a3f0-7440d2e54a44"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -q scikit-learn\n","!pip install -q pyannote.core\n","!pip install -q pyannote.metrics\n","!pip install -q seaborn\n","!pip install -q speechbrain"]},{"cell_type":"code","execution_count":null,"id":"762b815e-097d-4a71-9e0c-3ccd9c3ff3a5","metadata":{"id":"762b815e-097d-4a71-9e0c-3ccd9c3ff3a5","outputId":"63d5ab5c-fad6-4ddf-9f37-75005f0f384f"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'speechbrain.pretrained'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderClassifier\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speechbrain.pretrained'"]}],"source":["import os\n","import torchaudio\n","from speechbrain.pretrained import EncoderClassifier\n","import numpy as np\n","import math\n","from sklearn.cluster import KMeans\n","from pyannote.core import Annotation, Segment"]},{"cell_type":"code","execution_count":null,"id":"2515b478-e472-4325-bb27-91d65c269565","metadata":{"id":"2515b478-e472-4325-bb27-91d65c269565"},"outputs":[],"source":["# Функція для генерації RTTM файлу\n","def generate_rttm(audio_path, reference_rttm_path, output_directory, classifier, fs):\n","    n_clusters = read_num_speakers_from_rttm(reference_rttm_path)\n","    signal, _ = torchaudio.load(audio_path)\n","    segment_length = fs\n","    total_samples = signal.shape[1]\n","    num_segments = math.ceil(total_samples / segment_length)\n","    embeddings = []\n","\n","\n","    for i in range(num_segments):\n","        start = i * segment_length\n","        end = min(start + segment_length, total_samples)\n","        segment_length_actual = end - start\n","\n","        # Перевірка, чи сегмент має повну секунду\n","        if segment_length_actual != fs:\n","            continue  # Пропускаємо сегмент, якщо він коротший за секунду\n","\n","        segment = signal[:, start:end]\n","\n","        embedding = classifier.encode_batch(segment)\n","        embeddings.append(embedding.squeeze().cpu().detach().numpy())\n","\n","\n","    embeddings_array = np.array(embeddings)\n","    kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n","    kmeans.fit(embeddings_array)\n","    labels = kmeans.labels_\n","\n","    hypothesis = Annotation()\n","    for i, label in enumerate(labels):\n","        start = i\n","        hypothesis[Segment(start, start + 1)] = f\"spk{label}\"\n","\n","    file_id = os.path.basename(audio_path).split('.')[0]\n","    save_rttm(hypothesis, file_id, output_directory)"]},{"cell_type":"code","execution_count":null,"id":"8fc56e10-8a10-45cc-977d-d94f6929d6d2","metadata":{"id":"8fc56e10-8a10-45cc-977d-d94f6929d6d2"},"outputs":[],"source":["def save_rttm(annotation, file_id, output_directory):\n","    if not os.path.exists(output_directory):\n","        os.makedirs(output_directory)\n","\n","    file_path = os.path.join(output_directory, f\"{file_id}_hypothesis.rttm\")\n","    if not os.path.exists(file_path):\n","        with open(file_path, \"w\") as file:\n","            for segment, _, label in annotation.itertracks(yield_label=True):\n","                start = segment.start\n","                duration = segment.duration\n","                file.write(f\"SPEAKER {file_id} 1 {start:.2f} {duration:.2f} <NA> <NA> {label} <NA> <NA>\\n\")"]},{"cell_type":"code","execution_count":null,"id":"83106e8f-965e-4c23-8472-ecc96490e968","metadata":{"id":"83106e8f-965e-4c23-8472-ecc96490e968"},"outputs":[],"source":["# Функція для завантаження RTTM файлу та визначення кількості доповідачів\n","def read_num_speakers_from_rttm(rttm_file_path):\n","    speakers = set()\n","    with open(rttm_file_path, 'r') as file:\n","        for line in file:\n","            parts = line.strip().split()\n","            speaker_id = parts[7]\n","            speakers.add(speaker_id)\n","    return len(speakers)"]},{"cell_type":"code","execution_count":null,"id":"1103780a-7ffe-4c86-99cc-c9ba2a14a529","metadata":{"id":"1103780a-7ffe-4c86-99cc-c9ba2a14a529"},"outputs":[],"source":["# Ініціалізація моделі\n","classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"speechbrain\", run_opts={\"device\":\"cuda\"})\n","\n","wav_dir = \"voxconverse_test_wav\"\n","rttm_dir = \"voxconverse_test_rttm\"\n","output_directory = \"speechbrain_output_directory\"\n","\n","wav_files = [f for f in os.listdir(wav_dir) if f.endswith('.wav')]\n","audio_files = [os.path.join(wav_dir, f) for f in wav_files]\n","reference_rttm_files = [os.path.join(rttm_dir, f.replace('.wav', '.rttm')) for f in wav_files]\n","\n","wav_files = wav_files[42:]\n","audio_files = audio_files[42:]\n","reference_rttm_files = reference_rttm_files[42:]\n","\n","for audio_path, rttm_path in zip(audio_files, reference_rttm_files):\n","    print(rttm_path)\n","    generate_rttm(audio_path, rttm_path, output_directory, classifier, 16000)"]},{"cell_type":"code","execution_count":null,"id":"209197d2-f2b2-4ce2-933f-1d3dbf95db8b","metadata":{"id":"209197d2-f2b2-4ce2-933f-1d3dbf95db8b","outputId":"bba59969-f215-489e-f594-9ddbb383b7d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Diarization Error Rate: 0.31\n","Average Jaccard Error Rate: 0.41\n","Average Insertion Error Rate: 1.07\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Python Library</th>\n","      <th>Average Diarization Error Rate</th>\n","      <th>Average Jaccard Error Rate</th>\n","      <th>Average Insertion Error Rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>SpeechBrain</td>\n","      <td>0.308005</td>\n","      <td>0.406106</td>\n","      <td>1.067025</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Python Library  Average Diarization Error Rate  Average Jaccard Error Rate  \\\n","0    SpeechBrain                        0.308005                    0.406106   \n","\n","   Average Insertion Error Rate  \n","0                      1.067025  "]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","from pyannote.metrics.diarization import DiarizationErrorRate, JaccardErrorRate\n","from pyannote.metrics.identification import IdentificationErrorRate\n","\n","def load_rttm(file_path):\n","    annotation = Annotation()\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            parts = line.strip().split()\n","            start = float(parts[3])\n","            duration = float(parts[4])\n","            label = parts[7]\n","            annotation[Segment(start, start + duration)] = label\n","    return annotation\n","\n","rttm_folder = 'voxconverse_test_rttm'  # Шлях до папки з RTTM файлами\n","file_names = []\n","\n","# Перебір всіх файлів у папці\n","for file in os.listdir(rttm_folder):\n","    if file.endswith('.rttm'):\n","        # Додавання назви файлу без розширення .rttm до списку\n","        file_names.append(os.path.splitext(file)[0])\n","\n","# Створення екземпляра DiarizationErrorRate\n","der_metric = DiarizationErrorRate(collar=0.5)\n","jer_metric = JaccardErrorRate(collar=0.5)\n","ier_metric = IdentificationErrorRate(collar=0.5)\n","\n","# Масив для зберігання значень DER для кожної пари\n","error_rates_der = []\n","error_rates_jer = []\n","error_rates_ier = []\n","\n","for file_name in file_names:\n","    reference_path = f'voxconverse_test_rttm/{file_name}.rttm'\n","    hypothesis_path = f'speechbrain_output_directory/{file_name}_hypothesis.rttm'\n","\n","    reference_annotation = load_rttm(reference_path)\n","    hypothesis_annotation = load_rttm(hypothesis_path)\n","\n","    # Calculate metrics\n","    der = der_metric(reference_annotation, hypothesis_annotation)\n","    jer = jer_metric(reference_annotation, hypothesis_annotation)\n","    ier = ier_metric(reference_annotation, hypothesis_annotation)\n","\n","    error_rates_der.append(der)\n","    error_rates_jer.append(jer)\n","    error_rates_ier.append(ier)\n","\n","# Розрахунок середнього DER\n","average_der = sum(error_rates_der) / len(error_rates_der)\n","print(f\"Average Diarization Error Rate: {average_der:.2f}\")\n","\n","average_jer = sum(error_rates_jer) / len(error_rates_jer)\n","print(f\"Average Jaccard Error Rate: {average_jer:.2f}\")\n","\n","average_ier = sum(error_rates_ier) / len(error_rates_ier)\n","print(f\"Average Insertion Error Rate: {average_ier:.2f}\")\n","\n","df_result = pd.DataFrame([{\n","    'Python Library': 'SpeechBrain',\n","    'Average Diarization Error Rate': average_der,\n","    'Average Jaccard Error Rate': average_jer,\n","    'Average Insertion Error Rate': average_ier,\n","}])\n","\n","display(df_result)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}